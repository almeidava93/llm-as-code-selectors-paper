\begin{longtable}{lrllllrr}
\toprule
top_k & 10 & 20 & 50 & 100 & 200 & mean_f1_score & max_f1_score \\
model &  &  &  &  &  &  &  \\
\midrule
\endfirsthead
\toprule
top_k & 10 & 20 & 50 & 100 & 200 & mean_f1_score & max_f1_score \\
model &  &  &  &  &  &  &  \\
\midrule
\endhead
\midrule
\multicolumn{8}{r}{Continued on next page} \\
\midrule
\endfoot
\bottomrule
\endlastfoot
o3 & 0.8907 & 0.8767 & 0.8689 & 0.8874 &  & 0.8809 & 0.8907 \\
gpt-4.5-preview & 0.8741 & 0.8748 & 0.8801 & 0.8844 & 0.8792 & 0.8785 & 0.8844 \\
gpt-4.1-mini & 0.8741 & 0.8752 & 0.8677 & 0.8694 &  & 0.8716 & 0.8752 \\
Llama-4-Maverick-Instruct-Basic & 0.8575 & 0.8626 & 0.8626 & 0.8745 &  & 0.8643 & 0.8745 \\
gemini-2.0-pro-exp-02-05 & 0.8587 & 0.8579 & 0.8740 & 0.8668 & 0.8683 & 0.8652 & 0.8740 \\
gemma-3-27b-it & 0.8739 & 0.8592 & 0.8543 & 0.8329 &  & 0.8551 & 0.8739 \\
DeepSeek-V3 & 0.8643 & 0.8643 & 0.8692 & 0.8595 & 0.8725 & 0.8660 & 0.8725 \\
gemini-2.5-pro-exp-03-25 & 0.8603 & 0.8638 & 0.8693 & 0.8703 & 0.8721 & 0.8672 & 0.8721 \\
Llama-3.1-405B-Instruct & 0.8698 & 0.8634 & 0.8595 & 0.8615 &  & 0.8636 & 0.8698 \\
o3-mini & 0.8679 & 0.8591 & 0.8579 & 0.8697 & 0.8615 & 0.8632 & 0.8697 \\
Llama-4-Scout-Instruct-Basic & 0.8647 & 0.8663 & 0.8646 & 0.8556 &  & 0.8628 & 0.8663 \\
DeepSeek-R1 & 0.8487 & 0.8536 & 0.8548 & 0.8512 & 0.8660 & 0.8549 & 0.8660 \\
gpt-4.1 & 0.8658 & 0.8571 & 0.8638 & 0.8587 &  & 0.8614 & 0.8658 \\
gemini-2.0-flash-lite & 0.8543 & 0.8591 & 0.8595 & 0.8614 &  & 0.8586 & 0.8614 \\
sabia-3 & 0.8071 & 0.7947 & 0.7971 & 0.8607 &  & 0.8149 & 0.8607 \\
QwQ-32B & 0.8305 & 0.8357 & 0.8481 & 0.8441 & 0.8607 & 0.8438 & 0.8607 \\
gpt-4o-mini & 0.8599 & 0.8583 & 0.8548 & 0.8532 &  & 0.8566 & 0.8599 \\
Llama-3.1-70B-Instruct & 0.8571 & 0.8583 & 0.8587 & 0.8520 &  & 0.8566 & 0.8587 \\
Llama-3.3-70B-Instruct & 0.8552 & 0.8571 & 0.8583 & 0.8543 &  & 0.8562 & 0.8583 \\
sabiazinho-3 & 0.8465 & 0.8385 & 0.8579 & 0.8380 &  & 0.8452 & 0.8579 \\
o4-mini & 0.8559 & 0.8524 & 0.8476 & 0.8540 &  & 0.8525 & 0.8559 \\
o1 & 0.8539 & 0.8402 & 0.8547 & 0.8468 &  & 0.8489 & 0.8547 \\
gemma-2-27b-it & 0.8386 & 0.8539 & 0.8459 & 0.8401 &  & 0.8446 & 0.8539 \\
Llama-3-70B-Instruct & 0.8498 & 0.8531 & 0.8512 & 0.8465 &  & 0.8501 & 0.8531 \\
llama-3.2-1B-instruct-grpo-005-step-1000 & 0.8490 & 0.8487 & 0.8324 & 0.8023 &  & 0.8331 & 0.8490 \\
o1-mini & 0.8469 & 0.8321 & 0.8455 & 0.8443 &  & 0.8422 & 0.8469 \\
llama-3.2-1B-instruct-grpo-003 & 0.8357 & 0.8305 & 0.8245 & 0.8160 &  & 0.8267 & 0.8357 \\
gemini-2.0-flash & 0.8223 & 0.8329 & 0.8193 & 0.8315 &  & 0.8265 & 0.8329 \\
gpt-4.1-nano & 0.8321 & 0.8012 & 0.8093 & 0.7917 &  & 0.8086 & 0.8321 \\
gemma-3-4b-it & 0.8263 & 0.8225 & 0.8196 & 0.8012 &  & 0.8174 & 0.8263 \\
llama-3.2-1B-instruct-grpo-002 & 0.8083 & 0.8006 & 0.8132 &  &  & 0.8074 & 0.8132 \\
gpt-4o & 0.7732 & 0.7676 & 0.8071 & 0.8128 &  & 0.7902 & 0.8128 \\
llama-3.2-1B-instruct-grpo & 0.7940 & 0.7784 & 0.7428 & 0.7674 &  & 0.7707 & 0.7940 \\
llama-3.2-1B-instruct-grpo-001 & 0.7727 & 0.7778 & 0.7731 & 0.7630 &  & 0.7717 & 0.7778 \\
Llama-3.2-3B-Instruct & 0.7643 & 0.7771 & 0.6558 & 0.7393 &  & 0.7341 & 0.7771 \\
llama-3.2-1B-instruct-grpo-004-step-0050 & 0.6787 & 0.6829 & 0.7014 & 0.6880 &  & 0.6878 & 0.7014 \\
DeepSeek-R1-Distill-Qwen-7B & 0.6700 & 0.6156 & 0.6919 & 0.6972 &  & 0.6687 & 0.6972 \\
DeepSeek-R1-Distill-Qwen-1.5B & 0.5259 & 0.4753 & 0.3517 & 0.1311 &  & 0.3710 & 0.5259 \\
gpt-4o-baseline & 0.4440 &  &  &  &  & 0.4440 & 0.4440 \\
Llama-3.2-1B-Instruct & 0.0050 & 0.0000 & 0.0494 & 0.0390 &  & 0.0234 & 0.0494 \\
\end{longtable}
